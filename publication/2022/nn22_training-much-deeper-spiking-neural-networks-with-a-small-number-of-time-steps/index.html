<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jingyi Cui">

  
  
  
    
  
  <meta name="description" content="Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the &#34;quantization error&#34; and the &#34;deviation error&#34; into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the &#34;deviation error&#34; depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (&gt;100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of timesteps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks. ">

  
  <link rel="alternate" hreflang="en-us" href="https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-153875954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-153875954-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/logo-64.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="ZERO Lab">
  <meta property="og:url" content="https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/">
  <meta property="og:title" content="Training Much Deeper Spiking Neural Networks with a Small Number of Time-Steps | ZERO Lab">
  <meta property="og:description" content="Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the &#34;quantization error&#34; and the &#34;deviation error&#34; into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the &#34;deviation error&#34; depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (&gt;100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of timesteps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks. "><meta property="og:image" content="https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/featured.png">
  <meta property="twitter:image" content="https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2022-07-02T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2022-07-03T18:03:01&#43;08:00">
  

  


    











<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/"
  },
  "headline": "Training Much Deeper Spiking Neural Networks with a Small Number of Time-Steps",
  
  "image": [
    "https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/featured.png"
  ],
  
  "datePublished": "2022-07-02T00:00:00Z",
  "dateModified": "2022-07-03T18:03:01+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Qingyan Meng"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "ZERO Laboratory in Peking University",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ZERO-Lab-PKU.github.io/img/icon-512.png"
    }
  },
  "description": "Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the \"quantization error\" and the \"deviation error\" into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the \"deviation error\" depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (\u003e100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of timesteps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks. "
}
</script>

  

  


  


  





  <title>Training Much Deeper Spiking Neural Networks with a Small Number of Time-Steps | ZERO Lab</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">ZERO Lab</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#hero"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/post/"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/people/"><span>People</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/publication/"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <div class="pub">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Training Much Deeper Spiking Neural Networks with a Small Number of Time-Steps</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  
    
    
    
    <span><a href="/personwise/mengqingyan/">Qingyan Meng</a></span>
    
    
    
    , <span><a href="/personwise/yanshen/">Shen Yan</a></span>
    
    
    
    , <span><a href="/personwise/xiaomingqing/">Mingqing Xiao</a></span>
    
    
    
    , <span><a href="/personwise/wangyisen/">Yisen Wang</a></span>
    
    
    
    , <span><a href="/personwise/linzhouchen/">Zhouchen Lin</a></span>
    
    
    
    , <span>Zhi-Quan Luo</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June 2022
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  
    
  



<a class="btn btn-outline-primary my-1 mr-1" href="https://pdf.sciencedirectassets.com/271125/1-s2.0-S0893608022X00075/1-s2.0-S0893608022002064/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEC8aCXVzLWVhc3QtMSJIMEYCIQDJMRV4AfAZZWaVgICNKNPbZDbTjb2dsv6BgqtmXg%2B%2BWQIhAJXTjr8y%2FDq2QczGPWspOVaHeFY1XcRA3y%2BrSgJa3rmwKtIECFcQBBoMMDU5MDAzNTQ2ODY1Igw9fKa%2B5VuR3XecyZkqrwSSHbHJ8%2BxuwYkVB%2FKKwuvMIHJaCtZ4p6UyAp2CRmu4wuGh5BVq94Q0KMFLHAFVBM2yi8CCPWwqFzhr8G4stlZi9xWwvmaDIUfCW8N8qaokqdfULIBHDr9eRobGmj2tLZ%2FEK%2B3YLm2YLbma1LjUsrVInuEJRIytU8roR7vLlRP7ml5sy7Rx%2Fnttyh2EfpolnxBUyVTww5fZ4I6uyqaCKvZAb2QpbC8hcdfnZCg8TMt1QC57BieVtbYj6m2pdZ7AzR6yixm7dFDHvqHqsEbKwzuhtw5j1o414kHtI5Ace4sNOhosFGTlXFnYrKDF45sCYzn6HlBCcYH0FHFvLLBocjOgTVm0UIhDYcebGZCfg6pPJ8pzDFyYzV2jX1sYPnTvBur%2FA4yioD2HhXtuOZgTNryzk42zjzdcwUQXChi8EPspjys1izCLmlezHan1kxfFbMsLtvVD7ODtc3OSFBV9Zd6Gq1WhNdGDH0C1Xwd4ftnM8lGOAovai5YqSFINzk8sOKxkm%2FiZr%2FntN8WKWhAj0Dq8vF%2FYj1VuIotvsfH2XvjdetzgIzeLmwNWCSZN8%2BkLG7mele9Af7nnK9NuOo60%2Fu%2Fiihhj5K%2BEXdMp3Nas1tmVgK3Cgo%2Bl7lUGXJFz4HJd%2FLAdxZjsiaMTnXsM6NdwpxuyRymQZus4g8LxWQ1aMB0T4czNwXihh4hKOVBnAR3n6W5zFsH2NVrnCHWD1ffezWQeGxGWjrDsoKCjY3tjFsoVMI3D%2F5UGOqgBtHw52Fincyb2ZeSOoe30WK2kuGgiWd1hs7dnAPZa4rwjXi44xYWR%2BhQNKuafZuCWWj3RncZgofa4ltS%2F1FpfoONsWFYGoHYlvSzRdLFRdPLwBDJk%2FzZmJ4EmbBEVl1mBnCVxnyHa5Ml%2FTESNPCDxpsSLXdvuTnmN9zTNuossKHxV9YH4547Ei3KJG2DzX%2BtBT4XGDzfgTxvC6ahrYiZpfuARF4UeANDq&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20220702T074531Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY6N5ZVFDJ%2F20220702%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=81c2b79ee538733ba33283fbf823fc090189e91a8b7d6d05c96037eefa6fe150&amp;hash=e92ad2b0a0f0cb74c0c22948b9ca429e4c46d3a25fe30f645a538a6e2a77abbb&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0893608022002064&amp;tid=spdf-4696cb4d-8d25-4022-8fb1-0fa569584eed&amp;sid=89587cee4dfea645fe6bf38254f1ebeb303bgxrqa&amp;type=client&amp;ua=4d56505b0d5450025400&amp;rr=7245c32c6b787c97" target="_blank" rel="noopener">
  PDF
</a>

















</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 662px;">
  <div style="position: relative">
    <img src="/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/featured_hu8e51b3fb318eedaa77d80c8fd55e4445_61325_720x0_resize_lanczos_3.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the &ldquo;quantization error&rdquo; and the &ldquo;deviation error&rdquo; into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the &ldquo;deviation error&rdquo; depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (&gt;100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of timesteps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            
            
            <a href="/publication/#2">
              Journal article
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9">Neural Networks</div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/&amp;text=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/&amp;t=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps&amp;body=https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/&amp;title=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps%20https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://ZERO-Lab-PKU.github.io/publication/2022/nn22_training-much-deeper-spiking-neural-networks-with-a-small-number-of-time-steps/&amp;title=Training%20Much%20Deeper%20Spiking%20Neural%20Networks%20with%20a%20Small%20Number%20of%20Time-Steps" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  
    
  
  






  
  
  
  
  <div class="media author-card content-widget-hr">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/qingyan-meng/"></a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
  
</ul>

    </div>
  </div>







<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/publication/lihuan2023/2022_springer_alternating-direction-method-of-multipliers-for-machine-learning/" rel="next">Alternating Direction Method of Multipliers for Machine Learning</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/publication/2022/cvpr22_training-high-performance-low-latency-spiking-neural-networks-by-differentiation-on-spike-representation/" rel="prev">Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation</a>
  </div>
  
</div>

</div>



  
  



  </div>
</div>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.ac75b49cabdd0cbdaaf571f4c4fe7e35.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the <a href="https://xialipku.github.io">Xia Li</a> @ ZERO Lab,
    <a href="http://www.pku.edu.cn" target="_blank" rel="noopener">Peking University</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
