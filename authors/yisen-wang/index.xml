<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yisen Wang | ZERO Lab</title>
    <link>https://ZERO-Lab-PKU.github.io/authors/yisen-wang/</link>
      <atom:link href="https://ZERO-Lab-PKU.github.io/authors/yisen-wang/index.xml" rel="self" type="application/rss+xml" />
    <description>Yisen Wang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 28 Sep 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ZERO-Lab-PKU.github.io/img/icon-192.png</url>
      <title>Yisen Wang</title>
      <link>https://ZERO-Lab-PKU.github.io/authors/yisen-wang/</link>
    </image>
    
    <item>
      <title>Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_training_feedback_spiking_neural_networks_by_implicit_differentiation_on_the_equilibrium_state/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_training_feedback_spiking_neural_networks_by_implicit_differentiation_on_the_equilibrium_state/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reparameterized Sampling for Generative Adversarial Networks</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/ecml-pkdd21_reparameterized_sampling_for_generative_adversarial_networks/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/ecml-pkdd21_reparameterized_sampling_for_generative_adversarial_networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Demystifying Adversarial Training via A Unified Probabilistic Framework</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/icml21_demystifying_adversarial_training_via_a_unified_probabilistic_framework/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/icml21_demystifying_adversarial_training_via_a_unified_probabilistic_framework/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dissecting the Diffusion Process in Linear Graph Convolutional Networks</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_dissecting_the_diffusion_process_in_linear_graph_convolutional_networks/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_dissecting_the_diffusion_process_in_linear_graph_convolutional_networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Gauge Equivariant Transformer</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_gauge_equivariant_transformer/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_gauge_equivariant_transformer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Residual Relaxation for Multi-view Representation Learning</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_residual_relaxation_for_multi-view_representation_learning/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/nips21_residual_relaxation_for_multi-view_representation_learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improving Adversarial Robustness via Channel-wise Activation Suppressing</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_improving_adversarial_robustness_via_channel-wise_activation_suppressing/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_improving_adversarial_robustness_via_channel-wise_activation_suppressing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards A Unified Understanding and Improving of Adversarial Transferability</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_towards_a_unified_understanding_and_improving_of_adversarial_transferability/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_towards_a_unified_understanding_and_improving_of_adversarial_transferability/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unlearnable Examples: Making Personal Data Unexploitable</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_unlearnable_examples_making_personal_data_unexploitable/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2021/iclr21_unlearnable_examples_making_personal_data_unexploitable/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adversarial Weight Perturbation Helps Robust Generalization</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/neurips20_adversarial_weight_perturbation_helps_robust_generalization/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/neurips20_adversarial_weight_perturbation_helps_robust_generalization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Normalized Loss Functions for Deep Learning with Noisy Labels</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/icml20_normalized_loss_functions_for_deep_learning_with_noisy_labels/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0800</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/icml20_normalized_loss_functions_for_deep_learning_with_noisy_labels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improving Adversarial Robustness Requires Revisiting Misclassified Examples</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/iclr20_improving_adversarial_robustness_requires_revisiting_misclassified_examples/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0800</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/iclr20_improving_adversarial_robustness_requires_revisiting_misclassified_examples/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/iclr20_skip_connections_matter_on_the_transferability_of_adversarial_examples_generated_with_resnets/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0800</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/iclr20_skip_connections_matter_on_the_transferability_of_adversarial_examples_generated_with_resnets/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Symmetric Cross Entropy for Robust Learning with Noisy Labels</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/iccv19_symmetric_cross_entropy_for_robust_learning_with_noisy_labels/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0800</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/iccv19_symmetric_cross_entropy_for_robust_learning_with_noisy_labels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Convergence and Robustness of Adversarial Training</title>
      <link>https://ZERO-Lab-PKU.github.io/publication/2020/icml19_on_the_convergence_and_robustness_of_adversarial_training/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0800</pubDate>
      <guid>https://ZERO-Lab-PKU.github.io/publication/2020/icml19_on_the_convergence_and_robustness_of_adversarial_training/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
